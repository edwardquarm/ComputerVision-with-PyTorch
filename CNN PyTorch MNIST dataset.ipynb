{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de2e4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a90719",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torchvision.datasets.MNIST('./data',download=True, train=True,transform=ToTensor())\n",
    "data_test = torchvision.datasets.MNIST('./data',download=True, train=False,transform=ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=128)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a723edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, dataloader, lr = 0.01, optimizer =None, loss_fn = nn.NLLLoss()):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = lr)\n",
    "    net.train()\n",
    "    total_loss, acc, count = 0,0,0\n",
    "    for features, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        out = net(features)\n",
    "        loss = loss_fn(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc += (predicted == labels).sum()\n",
    "        count += len(labels)\n",
    "    return total_loss.item()/count, acc.item()/count\n",
    "\n",
    "def validate(net, dataloader, loss_fn = nn.NLLLoss()):\n",
    "    net.eval()\n",
    "    count,acc,loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in dataloader:\n",
    "            out = net(features)\n",
    "            loss += loss_fn(out,labels)\n",
    "            pred = torch.max(out,1)[1]\n",
    "            acc += (pred == labels).sum()\n",
    "            count += len(labels)\n",
    "    return loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd74b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_loader,test_loader,optimizer=None,lr=0.01,epochs=10,loss_fn=nn.NLLLoss()):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    res = { 'train_loss' : [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    for ep in range(epochs):\n",
    "        tl,ta = train_epoch(net,train_loader,optimizer=optimizer,lr=lr,loss_fn=loss_fn)\n",
    "        vl,va = validate(net,test_loader,loss_fn=loss_fn)\n",
    "        print(f\"Epoch {ep:2}, Train acc={ta:.3f}, Val acc={va:.3f}, Train loss={tl:.3f}, Val loss={vl:.3f}\")\n",
    "        res['train_loss'].append(tl)\n",
    "        res['train_acc'].append(ta)\n",
    "        res['val_loss'].append(vl)\n",
    "        res['val_acc'].append(va)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24e07716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "OneConv                                  --                        --\n",
       "├─Conv2d: 1-1                            [1, 9, 24, 24]            234\n",
       "├─Flatten: 1-2                           [1, 5184]                 --\n",
       "├─Linear: 1-3                            [1, 10]                   51,850\n",
       "==========================================================================================\n",
       "Total params: 52,084\n",
       "Trainable params: 52,084\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.19\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.04\n",
       "Params size (MB): 0.21\n",
       "Estimated Total Size (MB): 0.25\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OneConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1,out_channels=9,kernel_size=(5,5))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(5184,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv(x))\n",
    "        x = self.flatten(x)\n",
    "        x = nn.functional.log_softmax(self.fc(x),dim=1)\n",
    "        return x\n",
    "\n",
    "net = OneConv()\n",
    "summary(net,input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b24fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0, Train acc=0.951, Val acc=0.977, Train loss=0.001, Val loss=0.001\n",
      "Epoch  1, Train acc=0.979, Val acc=0.978, Train loss=0.001, Val loss=0.001\n",
      "Epoch  2, Train acc=0.986, Val acc=0.978, Train loss=0.000, Val loss=0.001\n",
      "Epoch  3, Train acc=0.988, Val acc=0.977, Train loss=0.000, Val loss=0.001\n",
      "Epoch  4, Train acc=0.991, Val acc=0.971, Train loss=0.000, Val loss=0.002\n"
     ]
    }
   ],
   "source": [
    "hist = train(net,train_loader,test_loader,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "880d25ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,9)\n",
    "with torch.no_grad():\n",
    "    p = next(net.conv.parameters())\n",
    "    for i,x in enumerate(p):\n",
    "        ax[i].imshow(x.detach().cpu()[0,...])\n",
    "        ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a41cad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MultilayerCNN                            --                        --\n",
       "├─Conv2d: 1-1                            [1, 10, 24, 24]           260\n",
       "├─MaxPool2d: 1-2                         [1, 10, 12, 12]           --\n",
       "├─Conv2d: 1-3                            [1, 20, 8, 8]             5,020\n",
       "├─MaxPool2d: 1-4                         [1, 20, 4, 4]             --\n",
       "├─Linear: 1-5                            [1, 10]                   3,210\n",
       "==========================================================================================\n",
       "Total params: 8,490\n",
       "Trainable params: 8,490\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.47\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.06\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultilayerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultilayerCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.fc = nn.Linear(320, 10)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1,320)\n",
    "        x = nn.functional.log_softmax(self.fc(x),dim=1)\n",
    "        return x\n",
    "net = MultilayerCNN()\n",
    "summary(net,input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8062ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0, Train acc=0.951, Val acc=0.978, Train loss=0.001, Val loss=0.001\n",
      "Epoch  1, Train acc=0.981, Val acc=0.977, Train loss=0.001, Val loss=0.001\n",
      "Epoch  2, Train acc=0.985, Val acc=0.982, Train loss=0.000, Val loss=0.001\n",
      "Epoch  3, Train acc=0.986, Val acc=0.983, Train loss=0.000, Val loss=0.001\n",
      "Epoch  4, Train acc=0.987, Val acc=0.984, Train loss=0.000, Val loss=0.001\n"
     ]
    }
   ],
   "source": [
    "hist = train(net,train_loader,test_loader,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89b0388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "244001e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataCIFAR/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataCIFAR/cifar-10-python.tar.gz to ./dataCIFAR\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./dataCIFAR', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "341f75a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=14, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=14, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "703e0e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LeNet                                    --                        --\n",
       "├─Conv2d: 1-1                            [1, 6, 28, 28]            456\n",
       "├─MaxPool2d: 1-2                         [1, 6, 14, 14]            --\n",
       "├─Conv2d: 1-3                            [1, 16, 10, 10]           2,416\n",
       "├─MaxPool2d: 1-4                         [1, 16, 5, 5]             --\n",
       "├─Conv2d: 1-5                            [1, 120, 1, 1]            48,120\n",
       "├─Flatten: 1-6                           [1, 120]                  --\n",
       "├─Linear: 1-7                            [1, 64]                   7,744\n",
       "├─Linear: 1-8                            [1, 10]                   650\n",
       "==========================================================================================\n",
       "Total params: 59,386\n",
       "Trainable params: 59,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.66\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.24\n",
       "Estimated Total Size (MB): 0.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16,120,5)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(120,64)\n",
    "        self.fc2 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = self.flat(x)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = LeNet()\n",
    "\n",
    "summary(net,input_size=(1,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be5c2688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0, Train acc=0.213, Val acc=0.234, Train loss=0.147, Val loss=0.143\n",
      "Epoch  1, Train acc=0.237, Val acc=0.242, Train loss=0.143, Val loss=0.142\n",
      "Epoch  2, Train acc=0.239, Val acc=0.259, Train loss=0.142, Val loss=0.139\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
    "hist = train(net, trainloader, testloader, epochs=3, optimizer=opt, loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078203cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
